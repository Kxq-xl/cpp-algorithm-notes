#  1. 操作系统概述

## 1.1 操作系统的基本概念

###  1.1.1 操作系统的概念

**操作系统是计算机的“管理者”和“中介”**，它负责协调和控制计算机的各种资源（如 CPU、内存、硬盘、输入输出设备等），同时向上为用户和程序提供一个**友好、统一的操作接口**。

**常见功能包括：**

1. **进程管理**：
    管理程序的运行，包括进程创建、调度、终止等。
2. **内存管理**：
    控制和分配内存资源，确保各程序合理使用内存，互不干扰。
3. **文件系统**：
    提供文件的创建、读写、存储等功能，便于数据管理。
4. **设备管理**：
    管理各种输入输出设备，如硬盘、打印机、键盘等。
5. **用户接口**：
    提供命令行或图形界面，让用户能与计算机交互。

常见的操作系统有: **Windows ** **Linux ** **macOS ** **Android / iOS（移动设备）**

### 1.1.2 操作系统的功能和目标

操作系统作为计算机系统资源的管理者

- 处理机管理
- 存储器管理
- 文件管理
- 设备管理

![image-20250807183551941](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250807183551941.png)

![image-20250807185430547](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250807185430547.png)

### 1.1.3 操作系统的特征

操作系统的特称： 并发 ，共享，虚拟，异步。

- **并发:**  指两个或者多个事件在同一时间间隔内发生，这些事件**宏观上是同时发生的**，但**微观上是交替发生的**。并行：是指两个时间在同一时刻同时发生。

![image-20250807191349209](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250807191349209.png)

**注意:**

单核CPU**同一时刻只能执行一个程序**，各个程序**并发**的执行。

多核CPU**同一时刻能执行多个程序**，多个程序可以**并行**执行。

- **共享**：共享即多个事件发生的时候，共同使用。资源共享主要分为**互斥共享**和**同时共享**。

微信和qq不能同时视频，这个就是互斥共享，不能同时占用摄像头。

但是可以同时发送文件，同时发送文件在宏观上是同时读取，同时发送，但并不是同时共享，它在微观上，两个进程是交替着访问硬盘的，这里传一会儿，那里传一下。所以磁盘是可共享资源，但访问是以并发+交替调度方式进行的

我们如果一遍打游戏，一遍听歌，这个扬声器确实是同时共享

**并发和共享是互为存在的条件**，只有并发了你才可以共享，你共享了，就必须并发才行。

- **虚拟： **把一个物理上的实体变为若干个逻辑上的对应物。物理实体(前者)是实际存在的，而逻辑上对应物（后者）是用户感受到的。

比如4g的内存，但你却能打开好多程序，他们运行内存远远大于4gb，这就是虚拟存储器技术。实际上只有4g，但用户看起来很大。 ------ 空分复用技术。

比如我们一个单核的CPU，物理上我们只能打开一个程序，但是逻辑上我们仍然可以打开很多很多的程序。 ----- 时分复用技术。

 ![image-20250807194931611](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250807194931611.png)

- **异步：**在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。

你需要打印文档A和B, 总有个先后，先打印A B则等待，系统资源有限，因此进程的执行不是一贯到底的。

## 1.2 操作系统的发展与分类

![image-20250808153041562](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250808153041562.png)

## 1.3 操作系统的运行环境

### 1.3.1 操作系统的运行机制

在操作系统中，cpu上会运行两种程序，一种是操作系统的**内核程序**，另一种是用户编写的**应用程序**。

**两种指令:**

- 特权指令: 是指不允许用户直接使用的指令，I/O指令，内存清零，修改程序状态寄存器等指令
- 非特权指令: 用户可以直接使用的指令，它不能直接访问系统的软硬件资源，防止破坏系统。

两种处理器状态：

- 内核态：运行的是内核程序，此时可以执行特权指令

- 用户态： 运行的是应用程序，只能执行非特权指令。

CPU中有一个寄存器叫做程序状态字寄存器(psw) 其中有一个二进制位，`1`表示内核态` 0`表示用户态。有些 CPU 设计是反过来的（比如 `0` 表示内核态，`1` 表示用户态），**具体取值要看 CPU 架构手册**。

![image-20250808161040012](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250808161040012.png)

### 1.3.2 中断和异常

在合适的情况下，操作系统内核会把cpu的使用权主动让给应用程序。

中断是让操作系统给内核夺回cpu使用权的**唯一途径**，中断会使cpu由用户态变为内核态。

中断分为**内中断（异常）**和**外中断**

- 内中断: 与当前执行的指令有关，中断信号来源于cpu内部。

试图在用户态下执行特权指令，当前的指令是非法的(**终止**)，或者参数是非法的(**故障**)。

应用程序想请求操作系统内核服务，此时会执行一条**陷入指令**，该指令会引发一个内部中断信号，**系统调用就是通过陷入指令完成的**。

- 外中断: 与当前执行的指令无关，中断信号来源于cpu外部。

时钟中断，I/O中断。

![image-20250808170047574](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250808170047574.png)

### 1.3.3 系统调用

系统调用是操作系统提供给程序(程序员)使用的接口。

系统调用的功能:

- 设备管理
- 文件管理
- 进程控制
- 进程通信
- 内存管理

![image-20250808172557614](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250808172557614.png)

![image-20250808172624360](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250808172624360.png)

## 1.4 操作系统体系结构

操作系统的体系结构有大内核(宏内核)，微内核，分层结构，模块化，外核。

- 分层结构： 每层单向调用更低一层所提供的接口，便于调试，易维护，但是效率低，不可跨层调用，效率低。
- 模块化：每个模块之间相互独立，有着清晰的结构，但是模块之间可能会出现相互调用的情况，一旦出了问题，调试和验证会有点麻烦。
- 大内核:  高性能，但是结构混乱，难以维护
- 微内核： 内核功能少，方便维护，但是多次状态切换，性能低。
- 外核: 可以直接给用户进程分配不虚拟不抽象的硬件资源，使用户进程更灵活的使用硬件资源，但它降低了系统的一致性，使系统变得复杂。

![image-20250811174934154](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250811174934154.png)

![image-20250811175156226](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250811175156226.png)

## 1.5 操作系统的引导

计算机中的主存由RAM(内存)和ROM组成。

| 对比项       | RAM（内存）              | ROM（只读存储器）                |
| ------------ | ------------------------ | -------------------------------- |
| 是否可写     | 读写都行（运行时可改）   | 一般只读（某些可擦写）           |
| 断电是否丢失 | 丢失（易失性）           | 不丢失（非易失性）               |
| 速度         | 很快                     | 较慢                             |
| 主要用途     | 存放正在运行的程序和数据 | 存放启动程序和固件(BIOS)自举程序 |
| 位置         | 内存条8G, 16G 32G        | 焊在主板上的芯片                 |

开机通电，cpu去找主存，然后里面的ROM引导程序会指示cpu去磁盘首位置将主引导记录和分区表读入到RAM(内存中去) 

然后cpu执行磁盘引导程序，然后根据分区表，去判断C盘所处的位置，然后在C盘中找到引导记录PBR，它会负责找到启动管理，在根目录下找到启动管理程序，然后就会完成操作系统初始化的工作。

![image-20250811194744778](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250811194744778.png)

## 1.6 虚拟机

![image-20250812105818489](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250812105818489.png)



## 总结：✅ **操作系统第1章 速记表**

### **1. 操作系统的定义与作用**

- **定义**：操作系统是管理计算机硬件与软件资源、提供用户和程序接口的系统软件。
- **作用**：
  1. 作为**用户与硬件的接口**（命令行、GUI）
  2. 作为**资源管理者**（CPU、内存、文件、设备等）
  3. 提供**服务**（系统调用、库函数）

------

### **2. 操作系统的特征**

- **并发性**：多个程序宏观上同时运行，微观上分时交替执行。
- **共享性**：系统资源可被多个用户或程序共同使用（互斥共享 & 同时共享）。
- **虚拟性**：通过抽象技术，让有限资源看起来更大或更简单（如虚拟内存、虚拟处理器）。
- **异步性**：进程执行走走停停，由 OS 调度，但结果可预测。

------

### **3. 操作系统的主要功能**

1. **进程管理**：进程/线程控制、调度、同步与通信。
2. **存储管理**：内存分配与回收、虚拟内存管理。
3. **文件管理**：文件存储、目录管理、访问控制。
4. **设备管理**：设备分配、驱动程序、中断处理。

------

### **4. 系统调用 vs API**

- **系统调用（System Call）**：
  - OS 提供给用户程序访问内核功能的**唯一接口**。
  - 通过陷入指令从用户态切换到内核态执行。
  - 例：`read()`, `write()`, `fork()`（Linux）
- **API（Application Programming Interface）**：
  - 应用程序调用的**函数接口**，可能封装了系统调用。
  - 例：C 标准库函数 `printf()` 内部会调用 `write()` 系统调用。
- **关系**：
   API 是高层接口，系统调用是 OS 提供的底层接口；API 可以调用系统调用，但不等于系统调用。
### **5. 并发 vs 并行**

- **并发（Concurrency）**：宏观同时、微观交替执行（单核 CPU 也能做到）。
- **并行（Parallelism）**：真正的同时执行（需要多核/多处理器）。

例子：

- 并发：一个 CPU 交替处理两个进程，看起来像同时进行。
- 并行：两个 CPU 核心分别同时执行两个进程。

------

### **6. 操作系统如何实现虚拟？**

- **虚拟内存**：用磁盘空间扩展物理内存，并给进程提供连续的地址空间抽象。
- **虚拟处理器**：多道程序设计，让每个进程看起来像独占 CPU。
- **虚拟设备**：用统一接口（驱动 + 虚拟文件系统）操作不同物理设备。

---

# 2. 进程与线程

## 2.1 进程和线程

### 2.1.1 进程的概念和组成

- 程序: 放在磁盘里面的可执行文件，是==静态==的。

- 进程: 是程序的一次执行过程， 是==动态==的。

当一个进程被创建的时候，操作系统会为此程序创建一个**唯一**的，**不重复**的ID --- **PID**。

**UID** 就是进程所属的用户。

![](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250813164833849.png)

上面所说的PID UID 以及图片中的cpu，磁盘，内存等等 都需要放在一个**进程控制块中(PCB)** PCB是进程存在的**唯一标志**。

![image-20250813165156689](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250813165156689.png)

**进程的组成: ** PCB、程序段、数据段。

PCB，是给操作系统用的，程序段和数据段是进程给自己用的。	

![image-20250813165918923](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250813165918923.png)

程序段、数据段、PCB三部分组成了进程实体(进程映像)。

进程是进程实体的运行过程，是系统进行资源分配和调度的一个单位。

### 2.1.2 进程的特征

程序是静态的，进程是动态的，相比于程序，进程拥有一下特征：

- 动态性：进程是程序的一次执行过程，是动态产生的，变化和消亡的。
- 并发性：内存中有个进程实体，各进程可以并发执行。
- 独立性：进程是能独立运行，独立获得资源，独立接受调度的基本单位
- 异步性：各进程各自独立的，不可预知的速度向前推进
- 结构性：每个进程都配置一个PCB，都由程序段和数据段 PCB组成。

### 2.1.3 进程的状态与转化

![image-20250813171633226](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250813171633226.png)

**状态：**

- 创建态：进程正在被创建，这个阶段操作系统会为进程分配资源，初始化PCB。
- 就绪态：进程已经创建完毕了，但由于没有空闲的CPU，就暂时不运行。
- 运行态：当CPU空闲下来，操作系统就会从处于就绪态的进程中，选择一个，进行运行，就叫运行态。
- 阻塞态：在进程运行中，有可能会**请求某个事件的发生**，所以在这个事件发生之前，CPU会使这个进程下去，让他变位阻塞态，然后CPU再选择一个就绪态的进程。当它等待的事情发生后，这个进程就又变回就绪态。
- 终止态：一个进程执行`exit` 请求操作系统终止进程，此时进程进入了终止态，然后让该进程下CPU，并回收内存空间等资源，最后回收PCB。

![image-20250813174231156](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250813174231156.png)

### 2.1.4 进程控制

进程控制就是 OS 用**原语**通过 PCB 对进程的**创建、运行、阻塞、唤醒、终止**进行管理，确保多进程在系统中**安全、高效、有序**地运行。

原语的执行必须一气呵成，不可中断。

**进程的创建**

- 分配进程控制块（PCB）
- 分配所需的内存和资源
- 初始化寄存器、程序计数器等运行环境
- 典型调用：`fork()`（Linux）

**进程的终止**

- 回收资源（内存、文件描述符等）
- 销毁 PCB
- 通知父进程进程结束状态

**进程的阻塞与唤醒**（成对出现）

- **阻塞**：进程等待某个事件（I/O 完成、信号等）而暂停运行
- **唤醒**：事件发生后让阻塞进程重新进入就绪队列

**进程的切换（上下文切换）**

- 保存当前进程的 CPU 环境（寄存器值、程序计数器等）
- 恢复下一个进程的运行环境

| 控制动作              | PCB 状态变化                       | 队列变化         |
| --------------------- | ---------------------------------- | ---------------- |
| **创建**（Create）    | 新建 PCB → 初始化状态              | 加入**就绪队列** |
| **撤销**（Terminate） | 释放 PCB → 回收资源                | 从所有队列移除   |
| **阻塞**（Block）     | 状态改为阻塞                       | 移入**阻塞队列** |
| **唤醒**（Wakeup）    | 状态改为就绪                       | 加入**就绪队列** |
| **切换**（Dispatch）  | 保存当前 PCB 寄存器值 → 加载新 PCB | 运行队列切换     |

无论哪个进程控制原语，要做的无非三类事情。

1. 更新PCB中信息
2. 将PCB插入合适的队列
3. 分配/回收资源

进程控制 = **PCB + 原语 + 队列管理**

### 2.1.5 进程通信(IPC)

进程间通信就是指两个进程或者多个进程之间产生的数据交互，

- 高级通信: **共享存储**，**消息传递**，**管道通信**, **套接字（Socket)(网络通信机制)**
- 低级通信: **信号量**，**信号**。

#### **高级通信**（侧重数据传输）

**共享存储：**

- 基于**数据结构**的共享：规定的类型，规定的长度，这种方式速度慢，限制多，是一种**低级通信**方式
- 基于**存储区**的共享：操作系统在内存中划出一块共享存储区，数据形式，存放位置都由进程控制，这种方式速度快，是一种**高级通信**方式。

**消息传递：**

- **直接通信**方式：消息发送进程要指明接受进程的ID

![image-20250814171206892](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250814171206892.png)

- **间接通信**方式：通过"信箱"间接地通信,可以多个进程往同一个信箱send消息，也可以从多个进程receive消息。

![image-20250814174123208](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250814174123208.png)

**管道通信：** 管道通信的管道是一个先进先出的队列(循环队列）。

- 管道的数据流向是一个单向的，称为**半双工通信**

![image-20250814180128171](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250814180128171.png)

- 如果要实现双向同时通信，则需要两个管道，称为**全双工通信**。

![image-20250814180025519](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250814180025519.png)

1. 各个进程要**互斥的**访问管道。
2. 当**管道写满**时，写进程将**阻塞**，直到读进程将管道的数据取走，即可唤醒写进程。
3. 当**管道读空**时，读进程将**阻塞**，直到写进程往管道中写入数据，就可唤醒读进程。

![image-20250814180927052](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250814180927052.png)

#### **低级通信**（侧重同步 & 事件通知）

- 信号量 - 实现进程的同步，互斥。
- 信号 - 实现进程间通信。

信号用于通知进程某个特定的事件已经发生。进程收到一个信号后，对该信号进行处理。

1️⃣ 什么是信号

- 信号是**软件中断**，用于通知进程发生了某种事件。
- 可以由 **内核** 或 **其他进程** 发送。
- 被发送的进程**不需要提前等着**，它会在执行过程中被打断去处理信号，所以叫**异步**。

------

2️⃣ 信号的来源

1. **内核产生**
   - 硬件异常：除零错误 → `SIGFPE`
   - 访问非法内存：`SIGSEGV`
   - 子进程结束：`SIGCHLD`
2. **用户进程产生**
   - 通过系统调用 `kill()` 给某进程发信号
   - 通过终端快捷键：
     - `Ctrl+C` → `SIGINT`（中断）
     - `Ctrl+Z` → `SIGTSTP`（暂停）

------

3️⃣ 信号的常见类型（Linux）

| 信号名    | 编号 | 含义                               |
| --------- | ---- | ---------------------------------- |
| `SIGINT`  | 2    | 终端中断（Ctrl+C）                 |
| `SIGKILL` | 9    | 强制杀死进程（不可捕获、不可忽略） |
| `SIGTERM` | 15   | 终止进程（可处理）                 |
| `SIGSTOP` | 19   | 暂停进程（不可捕获）               |
| `SIGSEGV` | 11   | 段错误（非法内存访问）             |

------

4️⃣ 信号的处理方式

每当从内核态要转为用户态时，就会处理这些信号，进程可以选择：

1. **执行默认动作**（比如终止、暂停等）
2. **捕获信号**（自定义**信号处理函数**去处理）
3. **忽略信号**（除 `SIGKILL` 和 `SIGSTOP` 外）

------

5️⃣ 信号的作用

- **进程控制**：杀死、暂停、恢复进程
- **事件通知**：告诉进程某事件发生（如 I/O 完成）
- **错误处理**：异常情况立即打断进程执行

------

📌 **一句话记忆**
 信号 = 软件世界的“快递员”，异步送来事件通知，让进程立即响应，常用于控制和通知。

### 2.1.6 线程和多线程模型

**线程**是一个基本**CPU执行单元**，也是**程序执行流的最小单位**，引入线程后，不仅是进程之间可以**并发**，进程内的各**线程之间也可以并发**，从而进一步提升了**系统的并发性。**

![image-20250815130725938](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250815130725938.png)

**线程的主要属性**

1. **轻量级（Lightweight）**
   - 线程依赖进程而存在，创建/切换开销比进程小。
   - 同一进程内的线程共享资源（代码段、数据段、文件等）。
2. **共享性（Sharing）**
   - 同一进程的线程共享进程资源：
     - 地址空间
     - 打开的文件
     - 全局变量、堆内存
   - 但每个线程有自己的**栈**和**寄存器环境**，保证独立执行。
3. **独立性（Independence）**
   - 尽管共享资源，每个线程都有独立的执行流（程序计数器 PC + 栈）。
   - 一个线程崩溃可能影响整个进程（这是它和进程最大的区别）。
4. **并发性（Concurrency）**
   - 同一进程内多个线程可以并发执行。
   - 在多核 CPU 上，多个线程甚至可以**并行**运行。
5. **可调度性（Schedulability）**
   - 线程是操作系统调度的基本单位（多数现代 OS 都是**以线程为最小调度单位**）。
   - 每个线程可以有自己的优先级。
6. **轻便性（低开销）**
   - 线程切换时只需保存/恢复寄存器和栈指针，不涉及整个进程的上下文，所以效率高。

------

**📌 一句话总结**

线程 = 进程里的“小兵”：

- 共享资源（吃同一锅饭），
- 有自己独立的栈和执行流（各干各的活），
- 是操作系统调度的最小单位。



线程的实现方式: 用户级线程，内核级线程，混合实现。

- **1. 用户级线程：** 线程由**用户态的线程库**管理，操作系统内核并不知道有这些线程。

![](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250816085519309.png)

- [x]  优点：用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高。

- [ ] 缺点： 如上图中while循环中，要是有一个线程被阻塞，其他的线程也无法进行下去，所以并发度不高，多线程不可在多核处理机上并行运行。

- **2. 内核级线程：** 线程由**操作系统内核管理和调度**。内核为每个线程维护控制块

![image-20250816091314443](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250816091314443.png)

- [x] 优点: 当一个线程被阻塞后，别的线程还可以继续执行，并发能力强，多线程在多核处理机上并行执行。
- [ ] 一个用户进程会占用多个内核线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大。

- **3. 混合实现：**

**一对一模型**就是内核级线程。

**多对一模型**就是用户级线程。

**多对多模型：**用户线程不直接一一对应内核线程，而是通过运行时系统调度映射过去。 折中方案，结合了灵活性和高效性。

![image-20250816092549721](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250816092549721.png)

![image-20250816092622163](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250816092622163.png)

线程的状态迁移和进程几乎一样：

- **新建 → 就绪 → 运行 →（阻塞 ↔ 就绪）→ 终止**

---

### ✅ 进程 vs 线程区别表

| 对比维度     | **进程（Process）**                                      | **线程（Thread）**                                     |
| ------------ | -------------------------------------------------------- | ------------------------------------------------------ |
| **基本概念** | 资源分配的最小单位                                       | 程序执行的最小单位，依赖进程存在                       |
| **调度单位** | 进程是早期操作系统的调度单位                             | 现代操作系统以线程作为基本调度单位                     |
| **资源拥有** | 拥有独立的地址空间、文件描述符、代码段、数据段等         | 共享进程的资源（地址空间、文件），但有独立的栈和寄存器 |
| **开销**     | 创建/撤销开销大，切换需要保存整个进程上下文              | 创建/撤销开销小，切换只需保存少量寄存器和栈指针        |
| **通信方式** | 需要借助 IPC（管道、消息队列、共享内存、信号等），开销大 | 共享内存（全局变量、堆）即可直接通信，简单高效         |
| **健壮性**   | 一个进程崩溃通常不会影响其他进程                         | 一个线程崩溃可能导致整个进程崩溃                       |
| **并发性**   | 进程之间可并发执行                                       | 一个进程内多个线程可并发执行                           |
| **典型应用** | 系统中的独立应用（浏览器、IDE、数据库服务）              | 应用内的任务单元（浏览器的标签页、IDE 的后台编译线程） |

------

📌 **一句话记忆**：

- 进程是“大房子”，线程是“房子里的工人”。
- 进程间**相互独立**，线程间**共享资源**。
- 调度和执行粒度 → **线程更轻量，更灵活**。

## 2.2 CPU调度

### 2.2.1 调度的概念

当有一堆任务要处理时候，但资源有限，这些事情没法同时处理，这就需要确定某种规则来决定处理这些任务的顺序，这就是**调度**研究的问题。

**调度的三个层次:**

- 高级调度(作业调度): 按一定的原则从外存的作业后备队列中挑选一个作业调入内存，并创建进程。**每个作业只调入一次，调出一次。**
- 中级调度(内存调度): 按照某种策略决定将哪个处于挂起状态的进程重新调入内存。
- 低级调度(进程调度): 按照某种策略从就绪队列中选取一个进程，将处理机分配给它。

暂时调到外村等待的进程状态为**挂起状态**。

![image-20250818145834360](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250818145834360.png)

![image-20250818150039849](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250818150039849.png)

### 2.2.2 进程调度的时机切换与过程调度方式

#### **进程调度的时机（需要调度时）**

操作系统会在以下情况触发调度器，从就绪队列中选一个新进程上 CPU：

1. **进程正常结束**
   - 进程运行完成，释放 CPU，需要选择下一个进程。
2. **进程阻塞**
   - 因 I/O 请求、等待事件、获取不到资源等进入阻塞状态。
3. **进程主动放弃 CPU**
   - 调用 `sleep()`、`yield()` 等，自己让出 CPU。
4. **时间片用完**（抢占式调度）
   - 分时系统里，当进程的时间片耗尽，系统强制切换。
5. **有更高优先级的进程就绪**
   - 抢占式调度策略下，高优先级进程到达，低优先级进程被剥夺 CPU。

**❌ 不会发生调度的情况**

有些特殊场景**不允许调度**，否则会破坏系统稳定性：

- 在 **中断处理过程** 中（防止上下文切换影响中断处理）
- 在 **操作系统内核临界区** 中（避免数据结构不一致）
- 在 **原子操作指令执行过程中**

-----

**临界区的一般概念**

- 临界区 = 程序中访问 **共享资源** 的那段代码。
- 比如多个进程/线程访问一个共享变量、文件或缓冲区 → 就需要进入临界区，避免同时修改导致数据错乱。

------

**操作系统内核临界区**

- 指 **操作系统内核自己使用的关键数据结构** 所在的临界区。
- 例如：
  - 进程控制块（PCB）队列
  - 内存分配表
  - I/O 缓冲队列
- 这些数据是内核全局共享的，**如果被多个进程或中断同时修改，会导致内核数据结构损坏**。

所以，操作系统会在内核临界区中：

- **禁止调度**（不能切换进程）
- **禁止中断**（防止中断打断内核操作）

这样可以保证内核数据结构的一致性和安全性。

#### 进程调度的方式

进程调度的方式有两种，非剥夺调度方式和剥夺调度方式。

- 非剥夺调度方式(非抢占式): 只允许进程主动放弃处理机。
- 剥夺调度方式(抢占式): 当一个进程正在处理机上执行时，发现一个更重要的程序需要使用处理机，则立即暂停正在执行的程序，将处理机分配给更紧迫的那个进程。

#### 进程的切换与过程

进程的切换指操作系统把 **CPU 使用权** 从一个进程转移到另一个进程。

本质：保存当前进程的执行现场（上下文），再恢复另一个进程的上下文。

进程切换 = **保存当前进程现场 → 更新 PCB → 调度新进程 → 恢复新进程现场**。

注意，进程切换是有代价的，因此如果过于频繁的进行调度，切换，必然使系统的效率降低。

#### 调度器，闲逛进程

调度器是 **操作系统内核里的一个模块**，专门负责 **决定哪个进程获得 CPU 使用权**。负责挑选进程 → 谁上 CPU。

**闲逛进程**：当“没有人可挑”的时候，调度器就让闲逛进程上 CPU。

### 2.2.3 调度的目标

调度的目标(调度算法的评价指标)有CPU利用率，系统吞吐量，周转时间，等待时间，响应时间。

| 指标           | 含义                                | 目标（越好越怎样） | 适用场景               |
| -------------- | ----------------------------------- | ------------------ | ---------------------- |
| **CPU 利用率** | CPU 忙碌时间 ÷ 总时间               | 越高越好           | 批处理系统             |
| **系统吞吐量** | 单位时间内完成的作业数              | 越大越好           | 批处理系统             |
| **周转时间**   | 作业提交 → 完成的总时间             | 越短越好           | 批处理系统             |
| **等待时间**   | 作业在就绪队列里等待 CPU 的时间     | 越短越好           | 批处理系统、交互式系统 |
| **响应时间**   | 从用户提交请求 → 系统首次响应的时间 | 越短越好           | 交互式系统             |

### 2.2.4 调度算法

调度算法大致可以分为两类：

1. **适用于早期批处理系统（作业调度）的调度算法**
    这类算法主要关心对用户的公平性，如平均周转时间、平均等待时间等评价系统整体性能的指标，对于用户来说，交互性很差。典型算法包括：
   - **FCFS (先来先服务)** 
   - **SJF (短作业优先)**
   - **SRTN (最短剩余时间优先)**
   - **HRRN (高响应比优先)**

| 调度算法                | 算法思想                 | 算法规则                                            | 调度类型            | 是否抢占 | 优点                         | 缺点                                 | 是否会导致饥饿 |
| ----------------------- | ------------------------ | --------------------------------------------------- | ------------------- | -------- | ---------------------------- | ------------------------------------ | -------------- |
| FCFS (先来先服务)       | 按到达顺序执行           | 先到先服务，按到达时间排队执行                      | 作业调度 / 进程调度 | 非抢占   | 实现简单、公平               | 短作业可能等待时间长                 | 否             |
| SJF (短作业优先)        | 优先执行执行时间短的作业 | 按作业/进程长度排序，最短先执行                     | 作业调度 / 进程调度 | 非抢占   | 平均周转时间最短             | 可能饿死长作业，对执行时间估计要求高 | 是             |
| SRTN (最短剩余时间优先) | 抢占式 SJF               | 当前作业剩余时间比新到作业长时抢占                  | 作业调度 / 进程调度 | 抢占     | 平均周转时间更短，响应快     | 可能饿死长作业，切换频繁             | 是             |
| HRRN (高响应比优先)     | 优先执行响应比高的作业   | 响应比 = (等待时间 + 服务时间)/服务时间，选择最大者 | 作业调度 / 进程调度 | 非抢占   | 兼顾短作业和长作业，避免饥饿 | 计算响应比稍复杂                     | 否             |

2. **适用于交互式系统（进程调度）的调度算法**
    这类算法更注重系统的响应时间，公平性，平衡性等指标，典型算法包括：

- **RR (时间片轮转)**
- **优先级调度**
- **多级反馈队列调度**

| 调度算法        | 算法思想                               | 算法规则                                     | 调度类型            | 是否抢占 | 优点                               | 缺点                                  | 是否会导致饥饿 |
| --------------- | -------------------------------------- | -------------------------------------------- | ------------------- | -------- | ---------------------------------- | ------------------------------------- | -------------- |
| RR (时间片轮转) | 轮流分配 CPU 时间                      | 每个作业按时间片轮流执行，时间片用完换下一个 | 进程调度            | 抢占     | 公平，响应时间好，适合分时操作系统 | 时间片太大退化为 FCFS，太小切换开销大 | 否             |
| 优先级调度      | 优先级高的作业先执行                   | 根据作业或进程优先级选择下一个执行           | 作业调度 / 进程调度 | 可抢占   | 可以保证重要作业先执行             | 低优先级可能长期等待                  | 是             |
| 多级反馈队列    | 多个队列，不同优先级和时间片，动态调整 | 作业可在队列间移动，长作业逐渐降低优先级     | 进程调度            | 抢占     | 兼顾响应时间和公平性，适合混合负载 | 实现复杂                              | 是             |

### 2.2.5 多处理机调度

![image-20250819183112860](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250819183112860.png)

在多处理机应该追求的目标: **负载均衡**和**处理机亲和**。

- 负载均衡：尽可能让每个CPU都同等忙碌
- 处理机亲和性: 尽量让一个进程调度到同一个CPU上运行，让发挥CPU发中缓存的作用。

解决负载均衡和亲和性有两种方案。

#### 方案一 公共有序队列

- 所有CPU共享同一个就绪进程队列（位于内核区）
- 每个CPU时运行调度程序，从公共就绪队列中选择一个进程与运行。
- 每个CPU访问公共就绪队列时需要上锁（确保互斥）

- [x] 优点：可以天然的实现负载均衡

- [ ] 缺点：各个进程频繁切换CPU，‘亲和性’不好。

❓如何解决亲和性问题呢？

**软亲和**：进程**尽可能**在原 CPU 上运行，但可以迁移到其他 CPU

**硬亲和**：进程**必须**在指定 CPU 上运行，不允许迁移

#### 方案二 私有就绪队列 

- 每个CPU都有一个私有就绪队列
- CPU空闲时运行调度程序，从私有就绪队列中选择一个进程运行。

- [x] 优点：可以天然的实现亲和性

- [ ] 缺点：初始负载不均衡时，可能出现某些 CPU 队列空闲、某些 CPU 队列繁忙。

❓如何解决队列空闲或者队列繁忙呢？

**推迁移(push)** : 当发现别的CPU空闲，而一个很忙，就会从忙碌的CPU中推一些给空闲的CPU的就绪队列中。

**拉迁移(pull)** :  当发现CPU负载很低，就会从高负载的CPU的就绪队列中拉一些进程到自己的就绪队列。

![image-20250819190641935](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250819190641935.png)

---

## 2.3 进程同步与互斥

### 2.3.1 互斥和同步的基本概念

**1. 进程互斥（Mutual Exclusion）**

**概念**：

- 当多个进程需要访问**同一共享资源**（如内存数据、文件、打印机等）时，为了防止同时访问导致数据混乱，需要确保**在同一时间只有一个进程访问该资源**。
- 这个保证“同一时刻只有一个进程访问资源”的机制，就叫**互斥**。

进程互斥经典的临界区互斥模型，是由进入区，临界区，退出区，剩余区实现的，需要遵循空闲让进，忙则等待，有限等待，让权等待，这四个原则。

**举例**：

- 两个进程同时要修改银行账户余额，如果不加互斥，可能出现“钱多扣少加”的错误。互斥就保证了每次只有一个进程能修改账户余额。

------

**2. 进程同步（Process Synchronization）**

**概念**：

- 当多个进程之间存在**执行顺序依赖**时，需要保证进程按照某种顺序执行，这种协调机制叫**同步**。
- 简单来说，**同步是为了顺序正确，互斥是为了防止资源冲突**。

**举例**：

- 生产者-消费者问题：
  - 生产者先生产数据，再让消费者消费；
  - 消费者必须等到有数据才能消费。
- 这里就是同步：保证先后顺序正确。

| 特性     | 进程互斥             | 进程同步                   |
| -------- | -------------------- | -------------------------- |
| 目的     | 防止共享资源冲突     | 保证执行顺序正确           |
| 关注点   | **同一时间访问冲突** | **先后执行顺序**           |
| 常用机制 | 锁、信号量、临界区   | 信号量、条件变量、消息队列 |
| 举例     | 银行账户操作         | 生产者-消费者问题          |

![image-20250820162347481](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820162347481.png)

### 2.3.2 互斥的实现方法

#### 软件实现方法

- 单标志法：

算法思想：两个进程在**访问完临界区后**会把使用临界区的**权限交给另一个进程**，也就是说每个进程进入临界区的权限**只能被另一个进程赋予**。

![image-20250820163857169](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820163857169.png)

但是如果此时轮到P0进程使用，但P0一直不使用(占着茅坑不拉屎)，而P1要用却进不去了。

所以**违背了“空闲让进”原则**。

- 双标志先检查：

算法思想：设置一个布尔数组`flag[]`,数组中各个元素用来标记个进程想进入临界区的意愿。`flag[0] = true` 表示P0进程想进入临界区，`flag[1] = false` 表示P1进程不想进入临界区。

![image-20250820164558320](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820164558320.png)

但是进入区的检查和上锁两个处理不是一气呵成的，先检查后，上锁前可能会发生进程切换。此时就是同时访问临界区了。

所以**违背了“忙则等待”原则**。

- 双标志后检查：

算法思想: 双标志先检查的改版，因为上一个算法是先**检查后上锁**，无法一气呵成，所以人们又想到了先**上锁后检查**。

![image-20250820170549132](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820170549132.png)

虽然解决了"忙则等待"的问题，但是很有可能会发生一直卡在2 6 代码处，两个进程都想进入临界区，但是谁也不让谁，会因各进程都长期无法访问临界资源产生"饥饿"。

所以又**违背了"空闲让进"和"有限等待"**的原则。

- Peterson 算法：

结合双标志法，单标志法的思想，如果双方都争着想进入临界区，那可以让进程尝试"孔融让梨" 做一个有礼貌的进程。

![image-20250820171615508](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820171615508.png)

这个算法遵循了空闲让进，忙则等待，有限等待 三个原则，但是它如果进不了临界区，它会一直卡在while循环，一直在CPU上执行，占用CPU资源。

所以违背了“让权等待”的原则。

![image-20250820182111043](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820182111043.png)

#### 硬件实现方法

- 中断屏蔽方法：

利用"开/关中断指令"实现，强制的，不允许发生进程切换，因此不会发生两个同时访问临界区的情况。

![image-20250820183530045](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820183530045.png)

优点：简单，高效

缺点：不适用于多处理机，只适用于操作系统内核进程，不适用于用户进程(用户随便开关中断指令，很危险)



- TestAndSet(TS指令/TSL指令)

简称TS指令，这个指令使用**硬件实现**的，执行的过程不允许中断，只能一气呵成。

![image-20250820184614962](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820184614962.png)

这个和Peterson算法一样，违背了**“让权等待”**的原则。

-  

![image-20250820185014239](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820185014239.png)

这个和TS指令的思路几乎一致，缺点也一致。 

![image-20250820185322588](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250820185322588.png)

### 2.3.3 互斥锁

**互斥锁的目的**

- **核心目标**：保护 **临界区（Critical Section）**，防止多个进程/线程同时修改共享资源而产生 **竞态条件（Race Condition）**。
- **实现方式**：通过锁机制，让一次只有一个进程进入临界区。

 **自旋锁（Spinlock）**

自旋锁，是互斥锁的一种实现方式，尤其适合 **多处理器系统**。

特点：

1. **忙等待**：如果锁被占用，线程 **不会被挂起**，而是在 CPU 上循环检查锁是否释放 → 这叫“自旋”。
2. **低延迟**：多核系统下，如果锁很快释放，线程能立即进入临界区，比阻塞锁（挂起等待）效率高。
3. **占用 CPU**：自旋等待期间，CPU 一直在检查锁，**浪费 CPU**，不适合长时间持锁。

使用场景：

- **多核 CPU**，临界区很短 → 自旋锁很快就能获取锁
- **临界区很长或单核 CPU** → 不推荐自旋锁，应该使用阻塞锁

| 特性     | 自旋锁                   | 阻塞锁（传统互斥锁）       |
| -------- | ------------------------ | -------------------------- |
| CPU 消耗 | 会占用 CPU（忙等待）     | 不占用 CPU（挂起等待）     |
| 延迟     | 低，锁释放立即获取       | 高，线程被挂起和唤醒有开销 |
| 使用场景 | 多核、临界区短           | 单核或临界区长             |
| 实现     | 基于原子操作（TSL/Swap） | 基于操作系统调度           |

### 2.3.4 信号量

**信号量机制**是一种由操作系统提供的 **进程同步与互斥机制**，用来协调多个进程对共享资源的访问。

信号量其实就是一个变量，一对原语`wait(S)`和`signal(S)`括号里的信号量S其实就是函数调用时传入的一个参数。 wait和signal也简称P，V操作P(S),V(S);

信号量就是一个整数 + 两个操作（P/V），用来解决进程的 **互斥** 和 **同步** 问题，是操作系统里非常经典的同步原语。

#### 整形信号量

用一个**整数型**的变量作为信号量，用来表示系统中**某种资源的数量**。

![image-20250821154038596](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250821154038596.png)

它当S为0的时候就会一直等待，所以不满足"让权等待"会发生忙等。

#### 记录型信号量

整形信号量的缺陷是存在忙等，因此人们又提出了'记录型信号量'，即用**记录型数据结构表示的信号量**。

![image-20250821155414529](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250821155414529.png)

S.value 的初值表示系统中某种资源的数目，当发现S.value<0时表示该资源已分配完毕，因此程序调用block原语进行自我阻塞，主动放弃了处理机，并插入等待队列。所以遵循了“让权等待”原则，不会出现”忙等“现象。

**利用信号量实现进程同步:**

✅ 信号量的两个操作

- **P 操作（wait）**
  - **先执行 `S = S - 1`**
  - 如果结果 < 0 → 说明没有资源，进程阻塞，进入等待队列。
  - 如果结果 ≥ 0 → 说明有资源，进程继续执行。

👉 所以 **P 是执行前 --，再检查能不能继续**。

- **V 操作（signal）**
  - **先执行 `S = S + 1`**
  - 如果结果 ≤ 0 → 说明有进程在等，唤醒一个阻塞的进程。
  - 如果结果 > 0 → 说明没人在等，直接结束。

👉 所以 **V 是执行时 ++，然后可能会唤醒别人**。

![image-20250821165900527](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250821165900527.png)

![image-20250821170817323](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250821170817323.png)

### 2.3.5 进程同步与互斥经典问题

#### 1. 生产者消费问题

生产者，消费者共享一个初始为空，大小为n的缓冲区。

- 只有缓冲区没满时候，生产者才能把产品放入缓冲区，否则必须等待。
- 只有缓冲区不空时候，消费者才能从中取出产品，否则必须等待。
- 缓冲区是临界资源，各进程必须互斥的访问。

![image-20250821175601337](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250821175601337.png)

这是一个 **生产者-消费者问题**：**同步 + 互斥**（要先生产后消费，同时不能多个进程一起写缓冲区）。

#### 2. 多生产者多消费问题

本质和单个生产者/消费者 **一模一样**，区别是有多个进程在同时生产或消费。

![image-20250822155133036](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250822155133036.png)

 **多生产者-多消费者问题**：也是**同步 + 互斥**，只是进程更多。

#### 3. 读者写者问题

有读者和写者两组并发进程，共享一个文件。

- 允许多个读者可以同时对文件执行读操作。
- 只允许一个写者往文件中写信息
- 任一写者在完成写操作之前不允许其他读者或者写者工作
- 写者执行写操作前，应让已有的读者和写者全部退出。

![image-20250822163314231](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250822163314231.png)

但是如果源源不断的来读，一直有人读进程，可是只有conut = 0 时，也就是最后一个人读完后在可以解锁文件，写进程一直无法唤醒，就会造成'饥饿'的现象。

此时新增了一个 w 变量即可实现 “写优先”

![image-20250822164756429](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250822164756429.png)

**读者-写者问题**：**互斥（写独占）+ 条件同步（第一个读者/最后一个读者控制写）**。

#### 4. 哲学家进餐问题

**场景**：

- 5 个哲学家围着桌子坐，每人面前有一只筷子。
- 吃饭要两只筷子（左+右）。
- 如果大家都先拿左手筷子，就会 **死锁**（没人能吃）。

 **信号量设计**：

- `chopstick[i] = 1`（第 i 只筷子）
- 每个哲学家必须同时申请两只筷子才能吃。

如果哲学家同时拿筷子，就会出现死锁问题

![image-20250823090631238](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250823090631238.png)

**避免死锁的方法**：

- 限制最多 4 个哲学家同时拿筷子。
- 或者规定奇数号哲学家先拿左，偶数号先拿右

![image-20250823090431224](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250823090431224.png)

**哲学家进餐问题 = 死锁产生 + 死锁预防的经典案例**。

### 2.3.6 管程

信号量机制实现进程同步和互斥，编写程序困难，易出错，所以引入了“管程”这种高级同步机制。

**管程是一种特殊的软件模块**

1. 局部于管程的共享数据结构说明
2. 对该数据结构进行操作的一切过程
3. 对局部于管程的共享数据设置初始值的语句。
4. 管程有一个名字

~~有点像C++中的类~~

**管程的基本特征**

1. 局部于管程的数据只能被局部于管程的过程所访问
2. 一个进程只有通过调用管程内的过程才能进入管程访问共享数据
3. **每次仅允许一个进程在管程内执行某个内部过程。**
4. 管程内部自动保证**互斥**，不用程序员自己写 `P/V`

**管程 = “自带锁的类” + “条件变量”**，自动实现互斥与同步。

| 特性         | **信号量（Semaphore）**        | **管程（Monitor）**                                    |
| ------------ | ------------------------------ | ------------------------------------------------------ |
| **定位**     | 低级同步原语，需要手动管理     | 高级同步工具，自动管理                                 |
| **使用方式** | 通过 `P()`、`V()` 控制访问     | 通过调用管程内过程访问                                 |
| **互斥实现** | 需要程序员显式用互斥信号量保护 | 管程内部自动互斥                                       |
| **同步实现** | 通过信号量计数实现             | 通过**条件变量** `wait()/signal()`                     |
| **难度**     | 容易出错（P/V顺序、死锁）      | 简单、安全                                             |
| **语言支持** | OS级特性，偏底层               | 高级语言直接支持（Java `synchronized`，C++条件变量等） |

## 2.4 死锁

### 2.4.1 死锁的概念

**死锁是各进程互相等待对方手里的资源，导致进程全部阻塞，无法向前推进。**

死锁，饥饿，死循环的共同点都是进程无法顺利向前推进(故意设计的死循环除外)

| 名称       | 产生原因                                        | 是否永远无法结束             | 典型场景                         |
| ---------- | ----------------------------------------------- | ---------------------------- | -------------------------------- |
| **死锁**   | 多个进程/线程相互等待资源，形成环路，无法推进。 | **是**（无外力不解开）       | 哲学家进餐、互斥锁环等           |
| **饥饿**   | 调度策略不公平，某进程长期得不到资源            | **不一定**（可能很久才执行） | 优先级调度低优先级任务长期不执行 |
| **死循环** | 程序逻辑错误，循环条件永远为真                  | **是**（除非人为打断）       | `while(1) {}`                    |

**关键点：**

- 必须是**多个进程/线程**参与。
- 每个进程都**持有部分资源**，又**请求其他资源**，形成**循环等待**。
- 一旦进入死锁状态，**没有外部干预无法自行解开**。

**经典例子：**
 两个进程A和B：

- A占有资源R1，请求R2；
- B占有资源R2，请求R1；
   二者相互等待，导致系统“卡死”。

| 死锁必要条件                   | 含义                           | 预防方法（破坏条件）                                     |
| ------------------------------ | ------------------------------ | -------------------------------------------------------- |
| **互斥条件**                   | 资源一次只能被一个进程占用     | 尽量使用**可共享资源**（如只读文件、SPOOLing假脱机技术） |
| **占有且等待条件**(请求和保持) | 进程持有资源的同时还申请新资源 | **一次性申请全部资源** 或 **先释放再申请**               |
| **不可剥夺条件**               | 已占有的资源不能强制剥夺       | **允许资源被强制剥夺**（如超时回收）                     |
| **循环等待条件**               | 存在资源等待环                 | **资源有序分配法**（按序号申请，避免环路）               |

**这四个条件必须同时满足，才可能发生死锁。**

**只要有一个条件不满足，就一定不会发生死锁。**

但**满足这四个条件 ≠ 一定死锁**，只是具备了发生死锁的可能。

**死锁的处理策略**

1. 预防死锁。破坏死锁产生的四个必要条件中的一个或者几个。
2. 避免死锁。用某种方法防止系统进入不安全状态，从而避免死锁（银行家算法）
3. 死锁的检测和解除。允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁。

### 2.4.2 预防死锁

**破坏互斥条件：**

互斥条件：只有对必须互斥使用的资源争抢才会导致死锁。

![image-20250825083022463](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825083022463.png)

缺点：并不是所有的资源都可以造成可共享的资源，并且为了系统安全，很多地方还必须保护这种互斥性。因此很多时候都无法破坏互斥条件。

**破坏不剥夺条件：**

不剥夺条件：进程所获得的资源在未使用前，不能由其他进程强行夺走，只能主动释放。

我们可以利用时间片轮转，或者调度优先级的方式破坏不剥夺条件。

缺点：

1. 实现起来比较复杂
2. 释放的已获得的资源，有可能造成前一阶段的资源失效。
3. 反复的申请和释放资源会增加系统开销，降低性能。

**破坏请求和保持条件**

请求和保持条件：进程在运行过程中已经**保持**了至少一个资源，需要**申请**新的资源，但是所需资源被其他进程占有，所以自己就会阻塞，但又对自己所占有的资源保持**不放**。

可以采取静态分配方法，就是进程在开始运行前，必须一次性申请完它所需的全部资源，在它的资源未满足之前，不能让它运行，一但运行起来，所占用的资源必须等待进程结束，才可以归还出去。

缺点：有些资源只需要占用很短的时间，但却一直被占用，所以会导致很**严重的资源浪费**，还会导致出现**饥饿**现象。

**破坏循环等待条件**

在系统中存在一个**进程—资源的环形等待链**，即：

- 进程 **P1** 等待 **P2** 占用的资源，
- **P2** 等待 **P3** 占用的资源，
- ……
- **Pn** 又等待 **P1** 占用的资源，
   形成一个**首尾相连的等待环路**。

**例子：**

- P1 占用 R1，等待 R2
- P2 占用 R2，等待 R3
- P3 占用 R3，等待 R1
   → 三个进程互相等待，谁都无法推进，系统陷入死锁。

**预防方法：**

- **资源有序分配法**：为资源统一编号，进程申请资源必须按编号递增（防止环路形成）。

**缺点：** 不方便增加新的设备，会导致资源浪费；用户编程麻烦。

### 2.4.3 避免死锁

**银行家算法（Banker’s Algorithm）是操作系统中**避免**死锁**的一种经典算法，由Dijkstra提出。它通过 **“安全状态”** 判断是否分配资源，保证系统始终不会进入死锁状态。

------

**1. 基本思想**

- 系统在每次分配资源时，都**先预判**此次分配是否会让系统进入不安全状态（可能死锁）。
- 如果分配后系统仍然有可能让**所有进程顺利完成**，则允许分配；否则拒绝本次分配，让进程等待。
- 类比“银行贷款”：银行只在保证最终能让所有客户都能还款的情况下才会放贷。

------

**2. 算法所需数据结构**

设系统有`n`个进程，`m`种资源：

- **Available[m]**：当前可用的各类资源数。
- **Max`[n][m]`**：每个进程对各类资源的最大需求。
- **Allocation`[n][m]`**：当前已分配给每个进程的资源数。
- **Need`[n][m]`**：每个进程还需的资源数 = `Max - Allocation`。

------

**3. 工作流程**

当一个进程请求资源时（Request[i]）：

1. **检查合法性**：
   - 若 `Request[i] <= Need[i]` 且 `Request[i] <= Available`，继续；否则非法请求。
2. **试分配**：
   - 先假设把资源分配给它：
     - `Available = Available - Request[i]`
     - `Allocation[i] = Allocation[i] + Request[i]`
     - `Need[i] = Need[i] - Request[i]`
3. **安全性检查**：
   - 判断系统是否处于安全状态（能否按某个顺序让所有进程执行完释放资源）。
   - 若安全 → 真正分配；
   - 若不安全 → 恢复原状态，让进程等待。

------

**4. 特点**

- 优点：能避免死锁发生。
- 缺点：需要事先知道每个进程的最大资源需求，开销较大，不适用于资源动态变化频繁的系统。

如果系统处于安全状态，就一定不会发生死锁。如果系统进入不安全状态，就可能发生死锁。

处于不安全状态未必就是发生了死锁，但发生了死锁一定是在不安全状态。

### 4.4.4 检测和解除

#### 死锁的检测

当系统**不采取预防或避免措施**时，需要定期或在资源不足时进行死锁检测。

**资源分配图（RAG）法**（适用于每类资源只有一个实例）

- **图中两类节点**：
  - **进程节点**（圆形）
  - **资源节点**（方形）
- **两类边**：
  - **请求边**（P → R）
  - **分配边**（R → P）

![](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825111335176.png)



- **检测方法**：
  - 在资源分配图中找是否有**环**，
  - **有环 ⇒ 必然死锁**（单实例资源）。

我们首先将图中即不阻塞，也不是孤点(至少有一条边)的进程，然后消去它所有的请求边和分配边，使之称为孤点，然后再找下一个不阻塞也不是孤点的点，依次重复，则称改图是**可完全简化**，否则就会产生死锁。

---

#### **死锁的解除**

一旦系统**检测到死锁**，常用的解决方法有：

1. **资源剥夺法（Resource Preemption）**
   - 挂起（暂时阻塞）某些死锁进程，并强制回收其占用的资源，分配给其他需要的进程。
   - **缺点**：可能导致**饥饿**，且状态恢复复杂。
2. **进程撤销法（Process Termination）**
   - 强制终止一个或多个死锁进程，释放其资源。
   - 策略：
     - 一次性终止所有死锁进程（简单粗暴，代价高）。
     - 按优先级、运行代价等因素逐个终止，直到死锁解除。
3. **进程回退法（Rollback）**
   - 系统在运行过程中为进程设置**检查点**，一旦发生死锁，回退到某个安全状态重新运行。
   - **缺点**：实现复杂，需要额外存储和恢复机制。

----

# 3. 内存管理

## 3.1 内存管理的概念

### 3.1.1 内存管理的基本原理和要求

#### 内存的基础知识

内存可存放数据，程序执行前需要先放到内存中才能被CPU处理，缓和CPU与硬盘之间的速度矛盾。 

#### 内存管理的概念

操作系统作为资源的管理者，需要管理那些？

1. 负责内存空间的分配与回收。
2. 提供某种技术从逻辑上对内存空间进行扩充(虚拟技术
3. 提供地址转换功能，负责程序的**逻辑地址**与**物理地址**的转换。   

![image-20250825164507373](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825164507373.png)

4. 内存保护，保证各进程在各自存储空间内运行，互不干扰。
   - 在CPU中设置一对上下限寄存器，存放进程的上，下限地址。进程的指令要访问某个地址时，CPU检查是否越界。
   - 采取重定位寄存器（**存放进程的起始物理地址**）和界地址寄存器（**存放进程中最大的逻辑地址**）

![image-20250825165428244](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825165428244.png)

#### 进程的内存映像

![image-20250825171402246](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825171402246.png)

`#define`不会单独分配空间，而是在编译的时候就将代码中的X替换成了1024了，它虽然放在紫色区域，但它和常量截然不同。 

```css
[ 进程 ]（内存）
-----内核区：
		----- 进程控制块PCB。
		----- 内核栈，内核数据结构
-----用户区
		-----用户栈：在函数大括号内定义的局部变量，函数调用时传入的参数。
		-----共享库的存储映射区：被调用的库函数
		-----堆：由malloc/free分配回收的数据
		-----未初始化的数据段（BSS）：未初始化的全局/静态变量
		-----已初始化数据段（Data）：已初始化的全局/静态变量
		-----只读代码/数据：程序代码。由const关键字修饰的常变量
-----未使用区（预留空间）
```

### 3.1.2 连续分配管理方式

连续分配：指为用户进程分配的必须是一个连续的内存空间。

#### 单一连续分配

内存被分为了**系统区**和**用户区**，内存中只能有一道用户程序，用户程序独占整个用户区域空间。如下图中，只能有一个进程A ![image-20250825180651411](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825180651411.png)

- 优点：实现简单，无外部碎片。
- 缺点：只能用于单用户，单任务的操作系统中，有内部碎片；存储器利用率低。

#### 固定分区分配

为了能在内存中装入多道程序，且这些程序之间又不会相互干扰，于是将整个用户空间划分为若干个固定大小的分区。

![image-20250825181522219](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825181522219.png)

- 分区大小相等：大小固定，不能满足不同大小的进程需求，缺乏灵活性。
- 分区大小不等：增加了灵活性，nice。

操作系统建立一个数据结构-----分区说明表，来实现各个分区的分配与回收，每个表项包括对应分区的大小，起始地址，状态（是否已分配）。

- 优点：实现简单，无外部碎片
- 缺点：当用户程序太大时候，可能所有分区都不满足，此时不得不采取覆盖技术来解决，但这又会降低性能，而且也会产生内部碎片，内存占用率低。

#### 动态分区分配

这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小**动态地建立分区**。

**操作系统用什么样的数据结构记录内存使用情况**

- 空闲分区表
- 空闲分区链

**当很多空闲分区都能满足需求时，应该选择哪个分区进行分配**

当一个新作业装入内存时，需按照**一定的动态分区分配算法**，从空闲分区表和空闲分区链中选择一个。

**如何进行分区的分配与回收**

如果两个空闲分区相邻，需要进行合并。如果回收区前后都有，同样也得合并。

如果回收前后都没有空闲分区，就需要新增空闲分区。

各表的顺序不一致，具体要看**动态分区分配算法**来确定。

- 动态分区没有内部碎片，但是有外部碎片，有些空闲分区太小了，虽然加起来满足，但是无法连续，所以用不上。 （可以通过紧凑技术来解决碎片）

![image-20250825185334093](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250825185334093.png)

#### 动态分区分配算法

**首次适应算法（First Fit）**

- **算法思想**：每次从低地址开始查找，找到第一个能满足大小的空闲分区。

- **算法实现：** 空闲分区以**按地址依次递增**，每次分配内存时顺序查找空闲分区链(分区表)，找到大小能满足要求的第一个空闲分区。

**最佳适应算法**

- **算法思想：**由于动态分区分配是一种连续分配方式，因此为了大进程到来能有连续的大片空间，可以尽可能多的留下大片的空闲区，优先使用小的空闲区。

- **算法实现：**空闲分区**按容量依次递增**，每次分配内存时，顺序查找空闲分区表(链)，找到大小能满足要求的第一个空闲分区。 

- 缺点：会留下越来越多，很小的，难以利用的碎片，产生了很多外部碎片。

**最坏适应算法**

- **算法思想:** 为了解决最佳适应算法产生的外部碎片，可以在每次分配优先使用最大的连续空闲区，这样分配后剩余的空闲就不会太小。
- **如何实现：** 空闲分区**按容量依次递减**，每次分配内存时，顺序查找空闲分区表(链)，找到大小能满足要求的第一个空闲分区。 
- 缺点：每次都选择大分区分配，但是如果大分区用完，之后又有大进程来了，就没有内存分区可以用了。

**邻近适应算法**

- **算法思想：** 首次适应算法每次都从链头开始查找，这也导致了低地址部分会出现很小的空闲分区，每次分配查找，都要经过这些分区，也增加查找的开销，如果可以每次都从上次查找结束的位置开始索引，就能解决上述问题。
- **算法实现：** 空闲分区**以地址递增排序**（可排成一个循环队列）每次从上次查找结束的位置开始查找空闲分区表(链)，找到一个合适的分区。

![image-20250826090429778](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826090429778.png)

### 3.1.3 基本分页存储管理

![](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826094115242.png)

将**内存**空间分为一个个**大小相等的分区**，每个分区就是**页框/页帧/物理块**，页框号从0开始。

将**进程的逻辑地址**空间也分为与页框大小相等的一个个部分，每个部分被称为**页/页面**页号也是从0开始。

操纵系统**以页框为单位为各个进程分配**内存空间，**进程的页面**与**内存的页框**有**一一对应**的关系。

各个页面**不必连续存放**，可以放到不相邻的各个页框中。

#### 页表

为了知道进程的每个页面在内存中哪里，操作系统为每一个进程创建了一种数据结构---**页表**，其存放在PCB（进程控制块）中。

![image-20250826100911647](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826100911647.png)

#### 快表

快表（又称联想**寄存器**），是一种访问速度比内存快很多的**高速缓存**，用来存放最近访问的**页表项的副本**，可以加速地址变换的速度，与此对应，内存中的页表常被称为**慢表**。

![image-20250826105228476](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826105228476.png)

![image-20250826110133509](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826110133509.png)

![image-20250826110207428](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826110207428.png)

**两级页表**

单级页表存在的问题

1. 页表必须连续存放，因此，当页表很大时，需要占用很多个连续的页框
2. 没必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面

我们可以为页表再次创建一个“页表”，称为**页目录表**，外层页表，顶层页表。

![image-20250826113238250](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826113238250.png)

![image-20250826113316821](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826113316821.png)

对于问题2，我们可以在需要访问页面的时候再把页面调入内存（虚拟内存存储技术） 给一个页表项增加一个标志位，若访问的页面不在内存，则产生缺页中断，然后将页面从外存调入内存。 

### 3.1.4 基本分段存储管理

进程的地址空间：按照程序**自身的逻辑关系划分为若干个段**，每个段都有一个段名(在低级语言中，程序使用段名来编程),每段从**0开始编址**。

内存分配规则：以段为单位进行分配，**每个段在内存中占据连续空间**，但**各段之间可以不相邻**。

#### 段表

程序分多个段，各段离散的装入内存，需从物理内存中找到各个逻辑段存放的位置，因此，每个进程建立了一张段映射表。--- ”**段表**“

1. 每个段对应一个段表项，其中记录了该段在内存中的**起始位置**(又称基址)和段长。
2. 各个段表项的长度是相同的，段号可以省略。

![image-20250826153357749](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826153357749.png)

段表也可以引入快表机构，加快地址变换速度。

#### 分页和分段的对比

**页是信息的物理单位**。分页的主要目的是**为了实现离散分配**，**提高内存利用率**。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可以见的。

**段是信息的逻辑单位**。分段的目的是**更好的满足用户需求**。一个段通常包含着一组属于一个逻辑块的信息。分段是对用户可见的，用户编程时需要显示给出段名。

---

页的大小固定且系统决定。

段的长度不固定，决定于用户编写的程序。

---

| 对比点         | 逻辑地址                   | 物理地址           |
| -------------- | -------------------------- | ------------------ |
| **谁生成**     | CPU（程序）                | 内存硬件           |
| **用户可见吗** | 用户/程序员可见            | 用户不可见         |
| **存在位置**   | 进程虚拟地址空间           | 真实内存单元       |
| **转换关系**   | 通过段表、页表、段页式映射 | 最终访问用物理地址 |

逻辑地址：

分页是由**页号和页内偏移**量组成。

分段是由**段号和段内偏移**量组成。

物理地址：

**分页**的用户进程地址空间为**一维**的，程序员只需要给出一个记忆符**表示地址**就好了。

**分段**的用户进程地址空间为**二维**的，需要标记**段长度**，和**段地址**。

---

**分段**比**分页**更容易实现信息的**共享和保护**，因为分段是按照逻辑划分，它共享和保护这段逻辑就好了，而分页很有可能出现整个页框中一半是需要保护的，另一半不需要保护，就会混乱。

----

### 3.1.5 段页式管理

![image-20250826162033226](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826162033226.png)

段页式系统的逻辑地址由段号，页号，页内地址(页内偏移量)组成。

- 段号的位数决定了每个进程最多可以分几个段
- 页号位数决定了每个段最大有多少页
- 页内偏移量决定了页面大小，内存块大小是多少。

每个段对应一个段表项，每个段表项由**段号**，**页表长度**，**页表存放块号(页表起始地址)**，注意每个段表长度相等，段号是隐含的。

每个页面对应一个页表项，里面含有页号，页面存放的内存块，每个页表项长度相同，页号也是隐含的。

![image-20250826164139964](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250826164139964.png)

| 特性         | 分页（Paging）                               | 分段（Segmentation）                       | 段页式（Segmentation with Paging）                         |
| ------------ | -------------------------------------------- | ------------------------------------------ | ---------------------------------------------------------- |
| **划分依据** | 按**固定大小的页**划分逻辑空间与物理内存     | 按**逻辑模块（段）**划分                   | 先按**逻辑段**划分，再在段内按**页**划分                   |
| **优点**     | 1. 消除**外部碎片**2. 支持虚拟内存，分配简单 | 1. 符合**程序逻辑**，支持**共享与保护**    | 1. 结合两者优点：既有**逻辑保护/共享**，又消除**外部碎片** |
| **缺点**     | 1. 产生**内部碎片**2. **共享/保护不灵活**    | 1. 产生**外部碎片**2. 段长不固定，管理复杂 | 1. 地址转换复杂（需两级查表）2. 硬件开销大                 |
| **透明性**   | **对程序员透明**                             | **对程序员可见**                           | 对程序员部分可见（逻辑上按段，物理上按页）                 |
| **地址结构** | **[页号, 页内偏移]**                         | **[段号, 段内偏移]**                       | **[段号, 页号, 页内偏移]**                                 |
| **典型用途** | 现代OS的**虚拟内存实现**                     | 提供模块级**共享/保护**                    | **现代主流处理器（x86）使用**，如段页结合管理内存          |

## 3.2 虚拟内存管理

### 3.2.1 虚拟内存的基本概念

**传统存储管理**有**连续分配**和**非连续分配**，很多用不到的数据也会长期占用内存，导致内存利用率不高。

- **一次性：**作业必须**一次性全部装入内存**后才能开始运行。如果作业很大，无法装入内存，则导致大作业无法运行。
- **驻留性：**一旦作业装入内存，**就会一直留在内存中**，直到作业结束，但事实上并不是进程中所有数据都要同时访问，有时候只需要一部分就行了，这就导致了浪费内存资源。

那上述的缺点，就可以用**虚拟存储技术**来解决。

在程序装入时，可以将程序中很快会用到的部分装入内存，暂时不用的部分留在外存。在执行过程中，所访问的信息**不存在**，再由操作系统将**所需信息从外存调入内存**，若内存空间**不足**，则由操作系统负责将**内存中暂时用不到的换出到外存**，在用户看来似乎比实际内存大的多，这就是**虚拟内存**，所以它具有以下三个特征：

- 多次性：作业无需一次性全部装入内存，可多次调入内存。
- 对换性：允许在作业运行过程中，将作业换入，换出。
- 虚拟性：从逻辑上扩充了内存，使用户看到的内存容量，远大于实际容量。

**虚拟内存的实现：**

- 请求分页存储管理
- 请求分段存储管理
- 请求段页式存储管理

### 3.2.2 请求分页管理方式

- 请求调页：当所需数据内存中不存在时，由操作系统从外存调入内存。
- 页面置换：当内存中空间不足时候，由操作系统将内存中暂时不用的页面换出外存。

这俩功能的实现，也需要一个数据结构来存储，在基本分页存储中有页表，在请求分页管理系统中也要有**页表**。

![image-20250827101647100](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827101647100.png)

![image-20250827103836942](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827103836942.png)



---

### 3.2.3 页面置换算法

当内存中满了，需要新加页面时，就需要用到**页面置换算法**，将内存中暂时不用的信息换出到外存。页面的换入，换出需要磁盘I/O，会有较大的开销，因此，应该**追求更少的缺页率**。

#### 最佳置换算法(OPT)

每次选择淘汰的页面都是**以后永不使用**，或者在**最长时间内不再被访问的页面**，这样可以保证最低的缺页率，但是操作系统无法预知未来啊，所以这个**算法是实现不了的**，只能模拟一下。

![image-20250827110806160](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827110806160.png)

#### 先进先出置换算法（FIFO）

每次选择**淘汰**的页面是**最早进入内存的页面**。

实现方式：把调入内存的页面根据调入的**先后顺序排成一个队列**，需要换出页面时选择**对头页面**即可，队列长度取决于系统为进程分配了多少个内存块。

![image-20250827112143907](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827112143907.png)

上图可以发现，为进程分配的物理块数增大时，缺页次数不减反增，这就是**Belady异常**所以它的性能很差。

#### 最近最久未使用置换算法（LRU）

每次**淘汰**的页面是**最近最久未使用的页面**。

实现方法：赋予每个页面对应的页表项，用访问字段记录该页面自**上次被访问以来所经历的时间t**,当需要淘汰页面时，选择有**页面t值最大的**，即**最久未使用的页面**。

![image-20250827113107258](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827113107258.png)

这个算法性能好，但实现困难，开销大，需要专门的硬件支持。

#### 时钟置换算法（CLOCK）

这是一种性能和开销比较均衡的算法，又称CLOCK算法或**最近未用算法**。

**简单的CLOCK算法实现**：在页面设置一个**访问位**，将内存中的页面链接成一个循环队列，当某页被访问时，设置为1，当需要页面置换的时候，就去队列中找，如果是0就换出，是1就设置为0暂不换出，这样子即使全为1，下一轮也有页面可换，所以这个算法**最多会进行两次扫描**。

![image-20250827115042106](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827115042106.png)

![image-20250827120730427](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827120730427.png)

简单时钟置换算法仅考虑到一个页面最近是否被访问过，而如果页面没有被修改，就不需要执行I/O操作写回外存。**只有淘汰的页面被修改过**，才需要写回外存。所以条件相同的时，**应优先淘汰没有修改过的页面**，避免I/O操作，这就是**改进时钟置换算法**的思想。修改位 = 1 / 0 表示修改/未修改。

（访问位，修改位）--->(1，1)表示近期访问又被修改。

算法实现：将所有可能被置换的页面排成一个循环队列，然后最多有**四轮扫描**，每轮失败则进行下一轮。

- 第一轮：寻找（0，0）`最近没有访问，没有修改的`不修改任何标志位，找到后进行置换。
- 第二轮：寻找（0，1）`最近没有访问，但修改过的`将访问位设置为0，若找到则进行替换。
- 第三轮：寻找（0，0）`最近访问过，没有修改`不修改任何标志位，找到后进行置换。
- 第四轮：寻找（0，1）`最近访问过，并且修改过的`肯定会找的，然后进行置换。

![image-20250827130916391](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827130916391.png)

---

### 3.2.4 页框分配

**驻留集：**指请求分页存储管理中给进程分配的物理块的集合。在采用虚拟存储技术的系统中，驻留集大小比进程大小要小。

驻留集太大，会导致多道程序并发度下降。驻留集太小，会导致缺页频繁。

#### **内存分配策略**

**固定分配：**操作系统为每个进程分配固定数目的物理块，在进程运行期间不可改变，即**驻留集大小不变**。

**可变分配：**先为每一个进程分配一定数目的物理块，在进程运行期间根据情况增加或减少，即**驻留集大小可变**。

**局部置换：**发生缺页时只能选进程**自己的物理块**进行置换。

**全局置换：**可以将**操作系统保留的空闲物理块**或者**别的进程的物理块**置换到外存，再分配给缺页进程。

上面可以搭配为，**固定分配局部置换**，**可变分配局部置换**，**可变分配全局置换**。

| 策略类型         | 页框分配是否可变 | 置换范围   | 优点               | 缺点         |
| ---------------- | ---------------- | ---------- | ------------------ | ------------ |
| 固定分配局部置换 | 否               | 本进程内部 | 独立性强，互不影响 | 资源利用率低 |
| 可变分配局部置换 | 是               | 本进程内部 | 灵活，效率较高     | 开销较大     |
| 可变分配全局置换 | 是               | 系统全局   | 利用率最高         | 进程互相影响 |

何时调入页面：

1. 预调页策略：**主要用于进程的首次调入**，由程序员指出应该调入哪些部分。
2. 请求调页策略：进程在每次发现缺页的时候才将所缺的页面调入内存。

何处调入页面：

1. 系统拥有足够对换区，页面的调入调出都是从对换区进行，速度快。
2. 系统缺少足够的对换区，凡是不会修改的数据，直接从文件区调入内存，对于可能修改的数据，进入对换区。
3. UNIX方式，运行进程之前，进程有关的数据全部放在文件区，页面第一次使用，是从文件区调入内存，如果置换的话，是换出到对换区。

刚刚换出页面又要换入内存，马上又要换出内存，这种频繁的页面调度就是**抖动**现象，主要原因就是分配给进程的物理块不够。

### 3.2.5 内存映射文件

内存映射文件 --- 操作系统像上层程序员提供的功能(系统调用)

**内存映射文件 是 将磁盘文件的一部分或全部映射到进程的虚拟内存空间**，从而允许进程**像访问内存一样直接读写文件内容**的一种技术。

- 方便程序员访问文件数据。
- 方便多个进程共享同一个文件。

![image-20250827162617635](https://cdn.jsdelivr.net/gh/Kxq-xl/pic-bed/img/image-20250827162617635.png)

----

